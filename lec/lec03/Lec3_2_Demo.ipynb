{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c397dc69-50aa-4572-9396-d5f410430142",
      "metadata": {
        "id": "c397dc69-50aa-4572-9396-d5f410430142"
      },
      "source": [
        "# Case Study: Python Demo - Implementing Gaussian Naive Bayes Assisted Spam Email Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb86790-14b0-4479-aed6-da85a5ac7cd7",
      "metadata": {
        "id": "5cb86790-14b0-4479-aed6-da85a5ac7cd7"
      },
      "outputs": [],
      "source": [
        "# Import Libraries and Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f3419f-6f80-4747-a740-3dd43b28b0d0",
      "metadata": {
        "id": "89f3419f-6f80-4747-a740-3dd43b28b0d0"
      },
      "source": [
        "# Create the experimental dataset for spam/non-spam email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f0c5ed-c586-4643-9142-252376b0aaa4",
      "metadata": {
        "id": "b7f0c5ed-c586-4643-9142-252376b0aaa4"
      },
      "outputs": [],
      "source": [
        "# Create the dataset--Using Panda's DataFrame\n",
        "# Step 1: Prepare a larger dataset\n",
        "data = {\n",
        "    'EmailID': np.arange(1, 21),\n",
        "    'WordCount': [350, 200, 500, 150, 300, 450, 600, 250, 550, 400, 700, 100, 450, 370, 650, 230, 510, 330, 600, 220],  # Example feature: Word count in email\n",
        "    'CapFrequency': [2, 1, 3, 0, 4, 2, 3, 1, 3, 0, 5, 0, 2, 3, 4, 1, 3, 2, 4, 1],  # Example feature: Capital letter frequency\n",
        "    'Spam': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # Target: 1 = Spam, 0 = Not Spam\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "djAzy3aCqIDl"
      },
      "id": "djAzy3aCqIDl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fdbb02d4-93b1-4328-86a8-82edd17c5de3",
      "metadata": {
        "id": "fdbb02d4-93b1-4328-86a8-82edd17c5de3"
      },
      "source": [
        "# Features and Labels and Split Data into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aee29860-26d3-44ae-ad96-33acc62eb1f4",
      "metadata": {
        "id": "aee29860-26d3-44ae-ad96-33acc62eb1f4"
      },
      "outputs": [],
      "source": [
        "# Features and target variable\n",
        "X = df[['WordCount', 'CapFrequency']]  # Features: WordCount, CapFrequency\n",
        "y = df['Spam']  # Target: Spam (1) or Not Spam (0)\n",
        "\n",
        "# Split into Training and Test Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the split sizes\n",
        "print(f\"Training Set Size: {X_train.shape}\")\n",
        "print(f\"Test Set Size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "901314ef-0bf7-4dcc-8bb4-f02fe1449786",
      "metadata": {
        "id": "901314ef-0bf7-4dcc-8bb4-f02fe1449786"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe40456d-7316-4ad2-add6-50bb1a2ce5e6",
      "metadata": {
        "id": "fe40456d-7316-4ad2-add6-50bb1a2ce5e6"
      },
      "outputs": [],
      "source": [
        "# Initialize the Gaussian Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Print the model parameters (mean and variance for each feature in each class)\n",
        "print(\"Model Parameters (Mean and Variance):\")\n",
        "print(f\"Class 0 (Not Spam) - Mean: {gnb.theta_[0]}, Variance: {gnb.var_[0]}\")\n",
        "print(f\"Class 1 (Spam) - Mean: {gnb.theta_[1]}, Variance: {gnb.var_[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5217676-ba8f-46b2-9c2f-3027c031ed9c",
      "metadata": {
        "id": "a5217676-ba8f-46b2-9c2f-3027c031ed9c"
      },
      "source": [
        "# Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac23bd15-4857-4045-be2a-3f0b8b9bdab4",
      "metadata": {
        "id": "ac23bd15-4857-4045-be2a-3f0b8b9bdab4"
      },
      "outputs": [],
      "source": [
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Print the predicted and actual labels\n",
        "print(\"\\nPredictions:\", y_pred)\n",
        "print(\"Actual Labels:\", y_test.values)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for Unseen Input Prediction"
      ],
      "metadata": {
        "id": "vJRYflokrwEk"
      },
      "id": "vJRYflokrwEk"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_email(word_count, cap_frequency):\n",
        "    \"\"\"Predict whether a single email is spam or not based on its features.\"\"\"\n",
        "    input_data = np.array([[word_count, cap_frequency]])\n",
        "    prediction = gnb.predict(input_data)[0]\n",
        "    return \"Spam\" if prediction == 1 else \"Not Spam\""
      ],
      "metadata": {
        "id": "Q5i5F5Wtr0oi"
      },
      "id": "Q5i5F5Wtr0oi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test single email prediction\n",
        "sample_email = (400, 2)  # Example: 400 words, 2 capital letters\n",
        "print(f\"\\nSingle Email Prediction: {predict_single_email(*sample_email)}\")"
      ],
      "metadata": {
        "id": "uCT1LX16r39k"
      },
      "id": "uCT1LX16r39k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_batch_emails(email_list):\n",
        "    \"\"\"Predict spam status for a batch of emails.\"\"\"\n",
        "    input_data = np.array(email_list)\n",
        "    predictions = gnb.predict(input_data)\n",
        "    return [\"Spam\" if pred == 1 else \"Not Spam\" for pred in predictions]"
      ],
      "metadata": {
        "id": "lVqyfN5rr7Zs"
      },
      "id": "lVqyfN5rr7Zs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test batch email prediction\n",
        "sample_batch = [(150, 1), (700, 5), (300, 2)]  # Example batch\n",
        "print(\"\\nBatch Email Predictions:\")\n",
        "print(predict_batch_emails(sample_batch))\n"
      ],
      "metadata": {
        "id": "xmjnhZR0r-6M"
      },
      "id": "xmjnhZR0r-6M",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (otter_env)",
      "language": "python",
      "name": "otter_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}